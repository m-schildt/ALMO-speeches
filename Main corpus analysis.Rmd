---
title: "data validation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
mydir = "speeches"
txtfiles = list.files(path=mydir, pattern="*.txt", full.names=TRUE)
txtfiles
```



```{r}
library(tidyr)
library(stringr)
library(dplyr)

parse_amlo <- function(file) {
  
  date <- substring(file, 10,19)
  try({
    speech <- readChar(file, file.info(file)$size)

    # This is the pattern that so far returns the speakers correctly
    pattern <- "([ A-ZÀ-Ú])+:"
    
    # Those were examples, now do this for the whole file to prep the speech for splitting
    prepped_speech <- str_replace_all(speech, pattern, "##\\0##")
    
    # This splits it row by row, but of course we need speaker and speech on the same column
    parsed_speech <- as.data.frame(str_split(prepped_speech, "##"), col.names = "A")
    
    parsed_speech <- parsed_speech %>%
      tail(-1)%>%  # remove first row  which has no speaker
      mutate(variable = rep(c("Speaker", "Text"), nrow(parsed_speech) / 2), 
           key = rep(1:(nrow(parsed_speech) / 2), each = 2)) %>%
      pivot_wider(id_cols = key, names_from = variable, values_from = A) %>% # divide speaker and text in separate columns 
      select(-key) %>% # remove helper 
      group_by(Speaker) %>% 
      summarize(Text = paste(Text, collapse = " ")) %>% # combine text of each speaker 
      mutate(Date = date, .before = Speaker)
    
    
    })
  
  return(parsed_speech)
  
  }

#test <- parse_amlo(txtfiles[1])
```


```{r}
# creates list
sample = lapply(txtfiles, parse_amlo)
# create data frame
sample_df <- do.call(rbind,lapply(txtfiles, parse_amlo))
# write csv from data frame
write.csv(sample_df,"sample_df.csv")

```

Load the df from the CSV
```{r}
sample_df2 <- read.csv(file = 'sample_df.csv', header = TRUE)%>%  
      select(-X)
```

create corpus with quanteda
```{r}
library("quanteda")
main_corpus <- corpus(sample_df2, text_field = "Text")
summary(main_corpus)

```

```{r}
#create tokens
main_tokens <-  tokens(main_corpus)
main_tokens_dfm <- dfm(main_tokens)
topfeatures(main_tokens_dfm, 50)

```


```{r}
#clean tokens - for illustration
main_tokens <- tokens(main_corpus, remove_punct = TRUE, remove_numbers = TRUE)
main_tokens <- tokens_select(main_tokens, stopwords('spanish'), selection='remove')
main_tokens_dfm <- dfm(main_tokens)
topfeatures(main_tokens_dfm, 50)
```


```{r}
#subset for president's speeches - 590 docs
subset_president <- (corpus_subset(main_corpus, Speaker == "PRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR:"))

#subset for 2020 and 2021 - 370 docs
subset_president_interim <- (corpus_subset(subset_president, Date > "2019-12-31"))

#subset for 2020 - 223 docs
subset_president_2020 <- (corpus_subset(subset_president_interim, Date < "2021-01-01"))
summary(subset_president_2020)

#subset for 2021 - 147 docs
subset_president_2021 <- (corpus_subset(subset_president, Date > "2020-12-31"))
summary(subset_president_2021)
```


##Analysis with President's Speeches in 2020 and 2021

```{r}
library("quanteda.textmodels")
library("quanteda.textstats")
library("quanteda.textplots")
library("ggplot2")

#tokens and df for 2020
tokens_president_2020 <- tokens(subset_president_2020, remove_punct = TRUE, remove_numbers = TRUE)
tokens_president_2020 <- tokens_select(tokens_president_2020, stopwords('spanish'), selection='remove')
dfm_president_2020 <- dfm(tokens_president_2020)

#tokens and df for 2021
tokens_president_2021 <- tokens(subset_president_2021, remove_punct = TRUE, remove_numbers = TRUE)
tokens_president_2021 <- tokens_select(tokens_president_2021, stopwords('spanish'), selection='remove')
dfm_president_2021 <- dfm(tokens_president_2021)

```

```{r}
#top features frequency plot
topfeatures(dfm_president_2020, 50)
dfm_features <- textstat_frequency(dfm_president_2020, n = 50)

dfm_features$feature <- with(dfm_features, reorder(feature, -frequency))

ggplot(dfm_features, aes(x = feature, y = frequency)) +
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

topfeatures(dfm_president_2021, 50)
dfm_features_2 <- textstat_frequency(dfm_president_2021, n = 50)

dfm_features_2$feature <- with(dfm_features_2, reorder(feature, -frequency))

ggplot(dfm_features_2, aes(x = feature, y = frequency)) +
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
#covid related freq plots with lexical dispersion - in progress

kwic(tokens(subset_president_2020), pattern = "pandemia")

kwic(tokens(subset_president_2020), pattern = "pandemia") %>%
    textplot_xray()

```

```{r}
#covid related word counts

library("janitor")

#matrix for covid related terms in 2020
covid_dic <- dictionary(list(all_terms = c("pandemia", "virus", "crisis", "covid", "sanitaria", "enfermedad")))
dfm_covid_2020 <- tokens(subset_president_2020) %>% tokens_select(covid_dic) %>% dfm()

dfm_covid_2020

##dfm_covid_2020 %>% adorn_totals(dfm_covid_2020, "row") - not sure what is wrong here
```

